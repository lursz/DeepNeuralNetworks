{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Zadanie:\n",
    "\n",
    "Proszę spróbować przeprowadzić taki proces regularyzacji modeli dla innego, nietrywialnego zbioru uczącego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0-dev20240315\n",
      "GPU Name :  []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print (\"TensorFlow version: \" + tf.__version__)\n",
    "print('GPU Name : ',tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n",
      "Keras version: 3.0.5\n",
      "GPU Name :  []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print (\"TensorFlow version: \" + tf.__version__)\n",
    "print (\"Keras version: \" + keras.__version__)\n",
    "print('GPU Name : ',tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "LABELS= ['0', '1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "For this excercice I'm going to use Hotel Reservations dataset.\n",
    "The goal is to predict whether the booking was cancelled or not.\n",
    "https://www.kaggle.com/datasets/ahsan81/hotel-reservations-classification-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36275, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>type_of_meal_plan</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>market_segment_type</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>no_of_previous_cancellations</th>\n",
       "      <th>no_of_previous_bookings_not_canceled</th>\n",
       "      <th>avg_price_per_room</th>\n",
       "      <th>no_of_special_requests</th>\n",
       "      <th>booking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Meal Plan 1</td>\n",
       "      <td>0</td>\n",
       "      <td>Room_Type 1</td>\n",
       "      <td>224</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Offline</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Not Selected</td>\n",
       "      <td>0</td>\n",
       "      <td>Room_Type 1</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>Online</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106.68</td>\n",
       "      <td>1</td>\n",
       "      <td>Not_Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Meal Plan 1</td>\n",
       "      <td>0</td>\n",
       "      <td>Room_Type 1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>Online</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0</td>\n",
       "      <td>Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Meal Plan 1</td>\n",
       "      <td>0</td>\n",
       "      <td>Room_Type 1</td>\n",
       "      <td>211</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>Online</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "      <td>Canceled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Selected</td>\n",
       "      <td>0</td>\n",
       "      <td>Room_Type 1</td>\n",
       "      <td>48</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>Online</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Canceled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_of_adults  no_of_children  no_of_weekend_nights  no_of_week_nights  \\\n",
       "0             2               0                     1                  2   \n",
       "1             2               0                     2                  3   \n",
       "2             1               0                     2                  1   \n",
       "3             2               0                     0                  2   \n",
       "4             2               0                     1                  1   \n",
       "\n",
       "  type_of_meal_plan  required_car_parking_space room_type_reserved  lead_time  \\\n",
       "0       Meal Plan 1                           0        Room_Type 1        224   \n",
       "1      Not Selected                           0        Room_Type 1          5   \n",
       "2       Meal Plan 1                           0        Room_Type 1          1   \n",
       "3       Meal Plan 1                           0        Room_Type 1        211   \n",
       "4      Not Selected                           0        Room_Type 1         48   \n",
       "\n",
       "   arrival_year  arrival_month  arrival_date market_segment_type  \\\n",
       "0          2017             10             2             Offline   \n",
       "1          2018             11             6              Online   \n",
       "2          2018              2            28              Online   \n",
       "3          2018              5            20              Online   \n",
       "4          2018              4            11              Online   \n",
       "\n",
       "   repeated_guest  no_of_previous_cancellations  \\\n",
       "0               0                             0   \n",
       "1               0                             0   \n",
       "2               0                             0   \n",
       "3               0                             0   \n",
       "4               0                             0   \n",
       "\n",
       "   no_of_previous_bookings_not_canceled  avg_price_per_room  \\\n",
       "0                                     0               65.00   \n",
       "1                                     0              106.68   \n",
       "2                                     0               60.00   \n",
       "3                                     0              100.00   \n",
       "4                                     0               94.50   \n",
       "\n",
       "   no_of_special_requests booking_status  \n",
       "0                       0   Not_Canceled  \n",
       "1                       1   Not_Canceled  \n",
       "2                       0       Canceled  \n",
       "3                       0       Canceled  \n",
       "4                       0       Canceled  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('HotelReservations.csv')\n",
    "data.drop(['Booking_ID'], axis=1, inplace=True)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['booking_status'] = data['booking_status'].map({'Canceled': 1, 'Not_Canceled': 0})\n",
    "# data['market_segment_type'] = data['market_segment_type'].map({'Online' : 1, 'Offline' : 0})\n",
    "# data['type_of_meal_plan'] = data['type_of_meal_plan'].map({'Not Selected' : 0, 'Meal Plan 1' : 1, 'Meal Plan 2' : 2, 'Meal Plan 3' : 3})\n",
    "# data['room_type_reserved'] = data['room_type_reserved'].str[-1].astype(int)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>...</th>\n",
       "      <th>booking_status</th>\n",
       "      <th>market_segment_Aviation</th>\n",
       "      <th>market_segment_Complementary</th>\n",
       "      <th>market_segment_Corporate</th>\n",
       "      <th>market_segment_Offline</th>\n",
       "      <th>market_segment_Online</th>\n",
       "      <th>meal_plan_Meal Plan 1</th>\n",
       "      <th>meal_plan_Meal Plan 2</th>\n",
       "      <th>meal_plan_Meal Plan 3</th>\n",
       "      <th>meal_plan_Not Selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>211</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_of_adults  no_of_children  no_of_weekend_nights  no_of_week_nights  \\\n",
       "0             2               0                     1                  2   \n",
       "1             2               0                     2                  3   \n",
       "2             1               0                     2                  1   \n",
       "3             2               0                     0                  2   \n",
       "4             2               0                     1                  1   \n",
       "\n",
       "   required_car_parking_space  room_type_reserved  lead_time  arrival_year  \\\n",
       "0                           0                   1        224          2017   \n",
       "1                           0                   1          5          2018   \n",
       "2                           0                   1          1          2018   \n",
       "3                           0                   1        211          2018   \n",
       "4                           0                   1         48          2018   \n",
       "\n",
       "   arrival_month  arrival_date  ...  booking_status  market_segment_Aviation  \\\n",
       "0             10             2  ...               0                    False   \n",
       "1             11             6  ...               0                    False   \n",
       "2              2            28  ...               1                    False   \n",
       "3              5            20  ...               1                    False   \n",
       "4              4            11  ...               1                    False   \n",
       "\n",
       "   market_segment_Complementary  market_segment_Corporate  \\\n",
       "0                         False                     False   \n",
       "1                         False                     False   \n",
       "2                         False                     False   \n",
       "3                         False                     False   \n",
       "4                         False                     False   \n",
       "\n",
       "   market_segment_Offline  market_segment_Online  meal_plan_Meal Plan 1  \\\n",
       "0                    True                  False                   True   \n",
       "1                   False                   True                  False   \n",
       "2                   False                   True                   True   \n",
       "3                   False                   True                   True   \n",
       "4                   False                   True                  False   \n",
       "\n",
       "   meal_plan_Meal Plan 2  meal_plan_Meal Plan 3  meal_plan_Not Selected  \n",
       "0                  False                  False                   False  \n",
       "1                  False                  False                    True  \n",
       "2                  False                  False                   False  \n",
       "3                  False                  False                   False  \n",
       "4                  False                  False                    True  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.get_dummies(data, columns=['booking_status'], prefix='booking_status')\n",
    "data = pd.get_dummies(data, columns=['market_segment_type'], prefix='market_segment')\n",
    "data = pd.get_dummies(data, columns=['type_of_meal_plan'], prefix='meal_plan')\n",
    "data['room_type_reserved'] = data['room_type_reserved'].str[-1].astype(int)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# min-max normalization:\n",
    "df=(df-df.min())/(df.max()-df.min())\n",
    "# mean normalization:\n",
    "df=(df-df.mean())/df.std()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>...</th>\n",
       "      <th>booking_status</th>\n",
       "      <th>market_segment_Aviation</th>\n",
       "      <th>market_segment_Complementary</th>\n",
       "      <th>market_segment_Corporate</th>\n",
       "      <th>market_segment_Offline</th>\n",
       "      <th>market_segment_Online</th>\n",
       "      <th>meal_plan_Meal Plan 1</th>\n",
       "      <th>meal_plan_Meal Plan 2</th>\n",
       "      <th>meal_plan_Meal Plan 3</th>\n",
       "      <th>meal_plan_Not Selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.298889</td>\n",
       "      <td>-0.261467</td>\n",
       "      <td>0.217398</td>\n",
       "      <td>-0.144801</td>\n",
       "      <td>-0.178817</td>\n",
       "      <td>-0.506404</td>\n",
       "      <td>1.614874</td>\n",
       "      <td>-2.137440</td>\n",
       "      <td>0.839230</td>\n",
       "      <td>-1.555641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.698052</td>\n",
       "      <td>-0.058802</td>\n",
       "      <td>-0.104384</td>\n",
       "      <td>-0.242642</td>\n",
       "      <td>1.563811</td>\n",
       "      <td>-1.333155</td>\n",
       "      <td>0.550642</td>\n",
       "      <td>-0.316607</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>-0.405843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.298889</td>\n",
       "      <td>-0.261467</td>\n",
       "      <td>1.365974</td>\n",
       "      <td>0.563964</td>\n",
       "      <td>-0.178817</td>\n",
       "      <td>-0.506404</td>\n",
       "      <td>-0.933688</td>\n",
       "      <td>0.467837</td>\n",
       "      <td>1.164974</td>\n",
       "      <td>-1.097998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.698052</td>\n",
       "      <td>-0.058802</td>\n",
       "      <td>-0.104384</td>\n",
       "      <td>-0.242642</td>\n",
       "      <td>-0.639446</td>\n",
       "      <td>0.750079</td>\n",
       "      <td>-1.816011</td>\n",
       "      <td>-0.316607</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>2.463936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.628953</td>\n",
       "      <td>-0.261467</td>\n",
       "      <td>1.365974</td>\n",
       "      <td>-0.853566</td>\n",
       "      <td>-0.178817</td>\n",
       "      <td>-0.506404</td>\n",
       "      <td>-0.980237</td>\n",
       "      <td>0.467837</td>\n",
       "      <td>-1.766723</td>\n",
       "      <td>1.419035</td>\n",
       "      <td>...</td>\n",
       "      <td>1.432519</td>\n",
       "      <td>-0.058802</td>\n",
       "      <td>-0.104384</td>\n",
       "      <td>-0.242642</td>\n",
       "      <td>-0.639446</td>\n",
       "      <td>0.750079</td>\n",
       "      <td>0.550642</td>\n",
       "      <td>-0.316607</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>-0.405843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.298889</td>\n",
       "      <td>-0.261467</td>\n",
       "      <td>-0.931177</td>\n",
       "      <td>-0.144801</td>\n",
       "      <td>-0.178817</td>\n",
       "      <td>-0.506404</td>\n",
       "      <td>1.463590</td>\n",
       "      <td>0.467837</td>\n",
       "      <td>-0.789491</td>\n",
       "      <td>0.503751</td>\n",
       "      <td>...</td>\n",
       "      <td>1.432519</td>\n",
       "      <td>-0.058802</td>\n",
       "      <td>-0.104384</td>\n",
       "      <td>-0.242642</td>\n",
       "      <td>-0.639446</td>\n",
       "      <td>0.750079</td>\n",
       "      <td>0.550642</td>\n",
       "      <td>-0.316607</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>-0.405843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298889</td>\n",
       "      <td>-0.261467</td>\n",
       "      <td>0.217398</td>\n",
       "      <td>-0.853566</td>\n",
       "      <td>-0.178817</td>\n",
       "      <td>-0.506404</td>\n",
       "      <td>-0.433285</td>\n",
       "      <td>0.467837</td>\n",
       "      <td>-1.115235</td>\n",
       "      <td>-0.525945</td>\n",
       "      <td>...</td>\n",
       "      <td>1.432519</td>\n",
       "      <td>-0.058802</td>\n",
       "      <td>-0.104384</td>\n",
       "      <td>-0.242642</td>\n",
       "      <td>-0.639446</td>\n",
       "      <td>0.750079</td>\n",
       "      <td>-1.816011</td>\n",
       "      <td>-0.316607</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>2.463936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_of_adults  no_of_children  no_of_weekend_nights  no_of_week_nights  \\\n",
       "0      0.298889       -0.261467              0.217398          -0.144801   \n",
       "1      0.298889       -0.261467              1.365974           0.563964   \n",
       "2     -1.628953       -0.261467              1.365974          -0.853566   \n",
       "3      0.298889       -0.261467             -0.931177          -0.144801   \n",
       "4      0.298889       -0.261467              0.217398          -0.853566   \n",
       "\n",
       "   required_car_parking_space  room_type_reserved  lead_time  arrival_year  \\\n",
       "0                   -0.178817           -0.506404   1.614874     -2.137440   \n",
       "1                   -0.178817           -0.506404  -0.933688      0.467837   \n",
       "2                   -0.178817           -0.506404  -0.980237      0.467837   \n",
       "3                   -0.178817           -0.506404   1.463590      0.467837   \n",
       "4                   -0.178817           -0.506404  -0.433285      0.467837   \n",
       "\n",
       "   arrival_month  arrival_date  ...  booking_status  market_segment_Aviation  \\\n",
       "0       0.839230     -1.555641  ...       -0.698052                -0.058802   \n",
       "1       1.164974     -1.097998  ...       -0.698052                -0.058802   \n",
       "2      -1.766723      1.419035  ...        1.432519                -0.058802   \n",
       "3      -0.789491      0.503751  ...        1.432519                -0.058802   \n",
       "4      -1.115235     -0.525945  ...        1.432519                -0.058802   \n",
       "\n",
       "   market_segment_Complementary  market_segment_Corporate  \\\n",
       "0                     -0.104384                 -0.242642   \n",
       "1                     -0.104384                 -0.242642   \n",
       "2                     -0.104384                 -0.242642   \n",
       "3                     -0.104384                 -0.242642   \n",
       "4                     -0.104384                 -0.242642   \n",
       "\n",
       "   market_segment_Offline  market_segment_Online  meal_plan_Meal Plan 1  \\\n",
       "0                1.563811              -1.333155               0.550642   \n",
       "1               -0.639446               0.750079              -1.816011   \n",
       "2               -0.639446               0.750079               0.550642   \n",
       "3               -0.639446               0.750079               0.550642   \n",
       "4               -0.639446               0.750079              -1.816011   \n",
       "\n",
       "   meal_plan_Meal Plan 2  meal_plan_Meal Plan 3  meal_plan_Not Selected  \n",
       "0              -0.316607              -0.011741               -0.405843  \n",
       "1              -0.316607              -0.011741                2.463936  \n",
       "2              -0.316607              -0.011741               -0.405843  \n",
       "3              -0.316607              -0.011741               -0.405843  \n",
       "4              -0.316607              -0.011741                2.463936  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_og = data.copy()\n",
    "\n",
    "data = (data - data.mean()) / data.std()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Validate - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>...</th>\n",
       "      <th>no_of_special_requests</th>\n",
       "      <th>market_segment_Aviation</th>\n",
       "      <th>market_segment_Complementary</th>\n",
       "      <th>market_segment_Corporate</th>\n",
       "      <th>market_segment_Offline</th>\n",
       "      <th>market_segment_Online</th>\n",
       "      <th>meal_plan_Meal Plan 1</th>\n",
       "      <th>meal_plan_Meal Plan 2</th>\n",
       "      <th>meal_plan_Meal Plan 3</th>\n",
       "      <th>meal_plan_Not Selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34727</th>\n",
       "      <td>-1.628953</td>\n",
       "      <td>-0.261467</td>\n",
       "      <td>1.365974</td>\n",
       "      <td>-0.853566</td>\n",
       "      <td>-0.178817</td>\n",
       "      <td>-0.506404</td>\n",
       "      <td>-0.980237</td>\n",
       "      <td>0.467837</td>\n",
       "      <td>-1.766723</td>\n",
       "      <td>1.419035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.788129</td>\n",
       "      <td>-0.058802</td>\n",
       "      <td>-0.104384</td>\n",
       "      <td>-0.242642</td>\n",
       "      <td>1.563811</td>\n",
       "      <td>-1.333155</td>\n",
       "      <td>0.550642</td>\n",
       "      <td>-0.316607</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>-0.405843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21428</th>\n",
       "      <td>0.298889</td>\n",
       "      <td>-0.261467</td>\n",
       "      <td>0.217398</td>\n",
       "      <td>-0.144801</td>\n",
       "      <td>-0.178817</td>\n",
       "      <td>-0.506404</td>\n",
       "      <td>2.382934</td>\n",
       "      <td>0.467837</td>\n",
       "      <td>-0.463746</td>\n",
       "      <td>0.160519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.788129</td>\n",
       "      <td>-0.058802</td>\n",
       "      <td>-0.104384</td>\n",
       "      <td>-0.242642</td>\n",
       "      <td>1.563811</td>\n",
       "      <td>-1.333155</td>\n",
       "      <td>0.550642</td>\n",
       "      <td>-0.316607</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>-0.405843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33234</th>\n",
       "      <td>2.226730</td>\n",
       "      <td>-0.261467</td>\n",
       "      <td>1.365974</td>\n",
       "      <td>-0.853566</td>\n",
       "      <td>-0.178817</td>\n",
       "      <td>-0.506404</td>\n",
       "      <td>0.614069</td>\n",
       "      <td>-2.137440</td>\n",
       "      <td>0.187742</td>\n",
       "      <td>0.732572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483754</td>\n",
       "      <td>-0.058802</td>\n",
       "      <td>-0.104384</td>\n",
       "      <td>-0.242642</td>\n",
       "      <td>1.563811</td>\n",
       "      <td>-1.333155</td>\n",
       "      <td>-1.816011</td>\n",
       "      <td>3.158405</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>-0.405843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11713</th>\n",
       "      <td>0.298889</td>\n",
       "      <td>-0.261467</td>\n",
       "      <td>-0.931177</td>\n",
       "      <td>-0.144801</td>\n",
       "      <td>-0.178817</td>\n",
       "      <td>-0.506404</td>\n",
       "      <td>-0.654393</td>\n",
       "      <td>0.467837</td>\n",
       "      <td>1.490718</td>\n",
       "      <td>-1.555641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.788129</td>\n",
       "      <td>-0.058802</td>\n",
       "      <td>-0.104384</td>\n",
       "      <td>4.121185</td>\n",
       "      <td>-0.639446</td>\n",
       "      <td>-1.333155</td>\n",
       "      <td>0.550642</td>\n",
       "      <td>-0.316607</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>-0.405843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>0.298889</td>\n",
       "      <td>-0.261467</td>\n",
       "      <td>-0.931177</td>\n",
       "      <td>-0.144801</td>\n",
       "      <td>5.592161</td>\n",
       "      <td>-0.506404</td>\n",
       "      <td>-0.887139</td>\n",
       "      <td>0.467837</td>\n",
       "      <td>0.187742</td>\n",
       "      <td>0.846982</td>\n",
       "      <td>...</td>\n",
       "      <td>1.755637</td>\n",
       "      <td>-0.058802</td>\n",
       "      <td>-0.104384</td>\n",
       "      <td>-0.242642</td>\n",
       "      <td>-0.639446</td>\n",
       "      <td>0.750079</td>\n",
       "      <td>-1.816011</td>\n",
       "      <td>-0.316607</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>2.463936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24520</th>\n",
       "      <td>0.298889</td>\n",
       "      <td>-0.261467</td>\n",
       "      <td>0.217398</td>\n",
       "      <td>-0.853566</td>\n",
       "      <td>-0.178817</td>\n",
       "      <td>-0.506404</td>\n",
       "      <td>-0.712580</td>\n",
       "      <td>0.467837</td>\n",
       "      <td>-1.440979</td>\n",
       "      <td>1.190214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483754</td>\n",
       "      <td>-0.058802</td>\n",
       "      <td>-0.104384</td>\n",
       "      <td>-0.242642</td>\n",
       "      <td>-0.639446</td>\n",
       "      <td>0.750079</td>\n",
       "      <td>0.550642</td>\n",
       "      <td>-0.316607</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>-0.405843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12514</th>\n",
       "      <td>2.226730</td>\n",
       "      <td>-0.261467</td>\n",
       "      <td>1.365974</td>\n",
       "      <td>-0.853566</td>\n",
       "      <td>-0.178817</td>\n",
       "      <td>3.065405</td>\n",
       "      <td>-0.363462</td>\n",
       "      <td>0.467837</td>\n",
       "      <td>0.839230</td>\n",
       "      <td>-0.754766</td>\n",
       "      <td>...</td>\n",
       "      <td>1.755637</td>\n",
       "      <td>-0.058802</td>\n",
       "      <td>-0.104384</td>\n",
       "      <td>-0.242642</td>\n",
       "      <td>-0.639446</td>\n",
       "      <td>0.750079</td>\n",
       "      <td>0.550642</td>\n",
       "      <td>-0.316607</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>-0.405843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21370</th>\n",
       "      <td>0.298889</td>\n",
       "      <td>-0.261467</td>\n",
       "      <td>-0.931177</td>\n",
       "      <td>-0.853566</td>\n",
       "      <td>-0.178817</td>\n",
       "      <td>0.207958</td>\n",
       "      <td>1.568325</td>\n",
       "      <td>0.467837</td>\n",
       "      <td>0.187742</td>\n",
       "      <td>-0.525945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.788129</td>\n",
       "      <td>-0.058802</td>\n",
       "      <td>-0.104384</td>\n",
       "      <td>-0.242642</td>\n",
       "      <td>-0.639446</td>\n",
       "      <td>0.750079</td>\n",
       "      <td>0.550642</td>\n",
       "      <td>-0.316607</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>-0.405843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15809</th>\n",
       "      <td>0.298889</td>\n",
       "      <td>-0.261467</td>\n",
       "      <td>1.365974</td>\n",
       "      <td>-0.853566</td>\n",
       "      <td>-0.178817</td>\n",
       "      <td>-0.506404</td>\n",
       "      <td>0.369686</td>\n",
       "      <td>-2.137440</td>\n",
       "      <td>0.187742</td>\n",
       "      <td>-1.670051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.788129</td>\n",
       "      <td>-0.058802</td>\n",
       "      <td>-0.104384</td>\n",
       "      <td>-0.242642</td>\n",
       "      <td>1.563811</td>\n",
       "      <td>-1.333155</td>\n",
       "      <td>-1.816011</td>\n",
       "      <td>3.158405</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>-0.405843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26235</th>\n",
       "      <td>-1.628953</td>\n",
       "      <td>-0.261467</td>\n",
       "      <td>-0.931177</td>\n",
       "      <td>-0.853566</td>\n",
       "      <td>-0.178817</td>\n",
       "      <td>-0.506404</td>\n",
       "      <td>-0.444923</td>\n",
       "      <td>0.467837</td>\n",
       "      <td>-1.115235</td>\n",
       "      <td>-0.411534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.788129</td>\n",
       "      <td>-0.058802</td>\n",
       "      <td>-0.104384</td>\n",
       "      <td>-0.242642</td>\n",
       "      <td>-0.639446</td>\n",
       "      <td>0.750079</td>\n",
       "      <td>0.550642</td>\n",
       "      <td>-0.316607</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>-0.405843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3628 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_of_adults  no_of_children  no_of_weekend_nights  no_of_week_nights  \\\n",
       "34727     -1.628953       -0.261467              1.365974          -0.853566   \n",
       "21428      0.298889       -0.261467              0.217398          -0.144801   \n",
       "33234      2.226730       -0.261467              1.365974          -0.853566   \n",
       "11713      0.298889       -0.261467             -0.931177          -0.144801   \n",
       "4977       0.298889       -0.261467             -0.931177          -0.144801   \n",
       "...             ...             ...                   ...                ...   \n",
       "24520      0.298889       -0.261467              0.217398          -0.853566   \n",
       "12514      2.226730       -0.261467              1.365974          -0.853566   \n",
       "21370      0.298889       -0.261467             -0.931177          -0.853566   \n",
       "15809      0.298889       -0.261467              1.365974          -0.853566   \n",
       "26235     -1.628953       -0.261467             -0.931177          -0.853566   \n",
       "\n",
       "       required_car_parking_space  room_type_reserved  lead_time  \\\n",
       "34727                   -0.178817           -0.506404  -0.980237   \n",
       "21428                   -0.178817           -0.506404   2.382934   \n",
       "33234                   -0.178817           -0.506404   0.614069   \n",
       "11713                   -0.178817           -0.506404  -0.654393   \n",
       "4977                     5.592161           -0.506404  -0.887139   \n",
       "...                           ...                 ...        ...   \n",
       "24520                   -0.178817           -0.506404  -0.712580   \n",
       "12514                   -0.178817            3.065405  -0.363462   \n",
       "21370                   -0.178817            0.207958   1.568325   \n",
       "15809                   -0.178817           -0.506404   0.369686   \n",
       "26235                   -0.178817           -0.506404  -0.444923   \n",
       "\n",
       "       arrival_year  arrival_month  arrival_date  ...  no_of_special_requests  \\\n",
       "34727      0.467837      -1.766723      1.419035  ...               -0.788129   \n",
       "21428      0.467837      -0.463746      0.160519  ...               -0.788129   \n",
       "33234     -2.137440       0.187742      0.732572  ...                0.483754   \n",
       "11713      0.467837       1.490718     -1.555641  ...               -0.788129   \n",
       "4977       0.467837       0.187742      0.846982  ...                1.755637   \n",
       "...             ...            ...           ...  ...                     ...   \n",
       "24520      0.467837      -1.440979      1.190214  ...                0.483754   \n",
       "12514      0.467837       0.839230     -0.754766  ...                1.755637   \n",
       "21370      0.467837       0.187742     -0.525945  ...               -0.788129   \n",
       "15809     -2.137440       0.187742     -1.670051  ...               -0.788129   \n",
       "26235      0.467837      -1.115235     -0.411534  ...               -0.788129   \n",
       "\n",
       "       market_segment_Aviation  market_segment_Complementary  \\\n",
       "34727                -0.058802                     -0.104384   \n",
       "21428                -0.058802                     -0.104384   \n",
       "33234                -0.058802                     -0.104384   \n",
       "11713                -0.058802                     -0.104384   \n",
       "4977                 -0.058802                     -0.104384   \n",
       "...                        ...                           ...   \n",
       "24520                -0.058802                     -0.104384   \n",
       "12514                -0.058802                     -0.104384   \n",
       "21370                -0.058802                     -0.104384   \n",
       "15809                -0.058802                     -0.104384   \n",
       "26235                -0.058802                     -0.104384   \n",
       "\n",
       "       market_segment_Corporate  market_segment_Offline  \\\n",
       "34727                 -0.242642                1.563811   \n",
       "21428                 -0.242642                1.563811   \n",
       "33234                 -0.242642                1.563811   \n",
       "11713                  4.121185               -0.639446   \n",
       "4977                  -0.242642               -0.639446   \n",
       "...                         ...                     ...   \n",
       "24520                 -0.242642               -0.639446   \n",
       "12514                 -0.242642               -0.639446   \n",
       "21370                 -0.242642               -0.639446   \n",
       "15809                 -0.242642                1.563811   \n",
       "26235                 -0.242642               -0.639446   \n",
       "\n",
       "       market_segment_Online  meal_plan_Meal Plan 1  meal_plan_Meal Plan 2  \\\n",
       "34727              -1.333155               0.550642              -0.316607   \n",
       "21428              -1.333155               0.550642              -0.316607   \n",
       "33234              -1.333155              -1.816011               3.158405   \n",
       "11713              -1.333155               0.550642              -0.316607   \n",
       "4977                0.750079              -1.816011              -0.316607   \n",
       "...                      ...                    ...                    ...   \n",
       "24520               0.750079               0.550642              -0.316607   \n",
       "12514               0.750079               0.550642              -0.316607   \n",
       "21370               0.750079               0.550642              -0.316607   \n",
       "15809              -1.333155              -1.816011               3.158405   \n",
       "26235               0.750079               0.550642              -0.316607   \n",
       "\n",
       "       meal_plan_Meal Plan 3  meal_plan_Not Selected  \n",
       "34727              -0.011741               -0.405843  \n",
       "21428              -0.011741               -0.405843  \n",
       "33234              -0.011741               -0.405843  \n",
       "11713              -0.011741               -0.405843  \n",
       "4977               -0.011741                2.463936  \n",
       "...                      ...                     ...  \n",
       "24520              -0.011741               -0.405843  \n",
       "12514              -0.011741               -0.405843  \n",
       "21370              -0.011741               -0.405843  \n",
       "15809              -0.011741               -0.405843  \n",
       "26235              -0.011741               -0.405843  \n",
       "\n",
       "[3628 rows x 24 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(data.drop(columns = ['booking_status']), data['booking_status'], test_size=0.2, random_state=42)\n",
    "val_data, test_data, val_labels, test_labels = train_test_split(test_data, test_labels, test_size=0.5, random_state=42)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weight(labels):\n",
    "    count_of_labels = len(labels)\n",
    "    count_of_positives = labels.sum()\n",
    "    count_of_negatives = count_of_labels - count_of_positives\n",
    "    \n",
    "    positive_weight = count_of_labels /  (2 * count_of_positives)\n",
    "    negative_weight = count_of_labels / (2 * count_of_negatives)\n",
    "    \n",
    "    return {0: negative_weight, 1: positive_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "Class weights: {0: 0.7436449364493645, 1: 1.5260832982751367}\n"
     ]
    }
   ],
   "source": [
    "class_weight = calculate_class_weight(data_og['booking_status'])\n",
    "print(1 / class_weight[0] + 1 / class_weight[1])\n",
    "print(f\"Class weights: {class_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive cases in total: 11885, negative cases in total: 24390, % of positive cases: 32.76%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Positive cases in total: {data_og['booking_status'].sum()}, negative cases in total: {len(data_og['booking_status']) - data_og['booking_status'].sum()}, % of positive cases: {data_og['booking_status'].sum() / len(data_og['booking_status']) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the confusion matrix for the results\n",
    "def show_confusion_matrix(validations, predictions, num_classes):\n",
    "    matrix = metrics.confusion_matrix(validations, predictions)\n",
    "    plt.figure(figsize=(num_classes, num_classes))\n",
    "    hm = sns.heatmap(matrix,\n",
    "                cmap='coolwarm',\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                xticklabels=LABELS,\n",
    "                yticklabels=LABELS,\n",
    "                annot=True,\n",
    "                fmt='d')\n",
    "    plt.yticks(rotation = 0)  # Don't rotate (vertically) the y-axis labels\n",
    "    hm.set_ylim(0, len(matrix))\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotThreeAccuracyComparison(acc1, val_acc1, acc2, val_acc2, acc3, val_acc3, lab1 = '1', lab2 = '2', lab3 = '3'):\n",
    "    plt.clf()   # clear figure\n",
    "    plt.rcParams['figure.figsize'] = (25.0, 5.0) # set default size of plots\n",
    "    epochs = range(1, len(acc1) + 1)\n",
    "    plt.plot(epochs, acc1, 'bo', label='Training accuracy for ' + lab1)\n",
    "    plt.plot(epochs, val_acc1, 'b', label='Validation accuracy for ' + lab1)\n",
    "    plt.plot(epochs, acc2, 'ro', label='Training accuracy for ' + lab2)\n",
    "    plt.plot(epochs, val_acc2, 'r', label='Validation accuracy for ' + lab2)\n",
    "    plt.plot(epochs, acc3, 'go', label='Training accuracy for ' + lab3)\n",
    "    plt.plot(epochs, val_acc3, 'g', label='Validation accuracy for ' + lab3)\n",
    "    plt.title('Comparison of Training and Validation Accuracies')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def PlotThreeLossComparison(loss1, val_loss1, loss2, val_loss2, loss3, val_loss3, lab1 = '1', lab2 = '2', lab3 = '3'):\n",
    "    plt.clf()   # clear figure\n",
    "    plt.rcParams['figure.figsize'] = (25.0, 5.0) # set default size of plots\n",
    "    epochs = range(1, len(loss1) + 1)\n",
    "    plt.plot(epochs, loss1, 'bo', label='Training loss for ' + lab1)\n",
    "    plt.plot(epochs, val_loss1, 'b', label='Validation loss for ' + lab1)\n",
    "    plt.plot(epochs, loss2, 'ro', label='Training loss for ' + lab2)\n",
    "    plt.plot(epochs, val_loss2, 'r', label='Validation loss for ' + lab2)\n",
    "    plt.plot(epochs, loss3, 'go', label='Training loss for ' + lab3)\n",
    "    plt.plot(epochs, val_loss3, 'g', label='Validation loss for ' + lab3)\n",
    "    plt.title('Comparison of Training and Validation Losses')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_history(history1, history2, history3, visualizer_function, field: str, label1: str, label2: str, label3: str):\n",
    "    value1 = history1.history[field]\n",
    "    value1_val = history1.history['val_' + field]\n",
    "    value2 = history2.history[field]\n",
    "    value2_val = history2.history['val_' + field]\n",
    "    value3 = history3.history[field]\n",
    "    value3_val = history3.history['val_' + field]\n",
    "\n",
    "    plt.figure(figsize=(25, 5))\n",
    "    visualizer_function(value1, value1_val, value2, value2_val, value3, value3_val, label1, label2, label3)\n",
    "\n",
    "def visualize_accuracy(history1, history2, history3, label1: str, label2: str, label3: str):\n",
    "    visualize_history(history1, history2, history3, PlotThreeAccuracyComparison, 'acc', label1, label2, label3)\n",
    "\n",
    "def visualize_loss(history1, history2, history3, label1: str, label2: str, label3: str):\n",
    "    visualize_history(history1, history2, history3, PlotThreeLossComparison, 'loss', label1, label2, label3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_val_accuracies(history1, history2, history3):\n",
    "    val_accuracy1 = history1.history['val_acc']\n",
    "    val_accuracy2 = history2.history['val_acc']\n",
    "    val_accuracy3 = history3.history['val_acc']\n",
    "\n",
    "    argmax1 = np.argmax(val_accuracy1)\n",
    "    argmax2 = np.argmax(val_accuracy2)\n",
    "    argmax3 = np.argmax(val_accuracy3)\n",
    "\n",
    "    print ('Max accuracy for model 1 is: ', val_accuracy1[argmax1], ', achieved in the ', argmax1 , 'epoch.')\n",
    "    print ('Max accuracy for model 2 is: ', val_accuracy2[argmax2], ', achieved in the ', argmax2 , 'epoch.')\n",
    "    print ('Max accuracy for model 3 is: ', val_accuracy3[argmax3], ', achieved in the ', argmax3 , 'epoch.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNNModel(input_shape: int, h1: int = 16, h2: int = 16, h3: int = 16):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(h1, activation='relu', input_shape=(input_shape,)))\n",
    "    model.add(layers.Dense(h2, activation='relu'))\n",
    "    model.add(layers.Dense(h3, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/Uni/DeepNeuralNetworks-Course/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,985</span> (39.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,985\u001b[0m (39.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,985</span> (39.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,985\u001b[0m (39.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1 = createNNModel(train_data.shape[1], 16, 16, 16)\n",
    "model2 = createNNModel(train_data.shape[1], 32, 32, 32)\n",
    "model3 = createNNModel(train_data.shape[1], 64, 64, 64)\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.0000e+00 - loss: 0.8531 - val_acc: 0.0000e+00 - val_loss: 0.1272\n",
      "Epoch 2/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: 0.1814 - val_acc: 0.0000e+00 - val_loss: -0.8512\n",
      "Epoch 3/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -0.8775 - val_acc: 0.0000e+00 - val_loss: -2.8232\n",
      "Epoch 4/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -2.9559 - val_acc: 0.0000e+00 - val_loss: -7.2108\n",
      "Epoch 5/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -7.9846 - val_acc: 0.0000e+00 - val_loss: -15.2395\n",
      "Epoch 6/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -15.6888 - val_acc: 0.0000e+00 - val_loss: -29.1039\n",
      "Epoch 7/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -30.4079 - val_acc: 0.0000e+00 - val_loss: -49.7006\n",
      "Epoch 8/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -51.8245 - val_acc: 0.0000e+00 - val_loss: -79.9036\n",
      "Epoch 9/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -80.4057 - val_acc: 0.0000e+00 - val_loss: -122.3634\n",
      "Epoch 10/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -118.8092 - val_acc: 0.0000e+00 - val_loss: -178.7309\n",
      "Epoch 11/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -174.9902 - val_acc: 0.0000e+00 - val_loss: -252.6451\n",
      "Epoch 12/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -246.0433 - val_acc: 0.0000e+00 - val_loss: -347.0768\n",
      "Epoch 13/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -327.3070 - val_acc: 0.0000e+00 - val_loss: -465.1137\n",
      "Epoch 14/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -444.4997 - val_acc: 0.0000e+00 - val_loss: -612.5193\n",
      "Epoch 15/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -595.1034 - val_acc: 0.0000e+00 - val_loss: -790.3294\n",
      "Epoch 16/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -748.6570 - val_acc: 0.0000e+00 - val_loss: -1003.4541\n",
      "Epoch 17/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -995.4999 - val_acc: 0.0000e+00 - val_loss: -1254.8292\n",
      "Epoch 18/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -1196.7134 - val_acc: 0.0000e+00 - val_loss: -1554.8899\n",
      "Epoch 19/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -1469.0444 - val_acc: 0.0000e+00 - val_loss: -1904.2847\n",
      "Epoch 20/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -1815.4951 - val_acc: 0.0000e+00 - val_loss: -2305.2805\n",
      "Epoch 21/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.0000e+00 - loss: -2149.7261 - val_acc: 0.0000e+00 - val_loss: -2767.9312\n",
      "Epoch 22/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -2604.4470 - val_acc: 0.0000e+00 - val_loss: -3294.3000\n",
      "Epoch 23/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -3029.8494 - val_acc: 0.0000e+00 - val_loss: -3903.8682\n",
      "Epoch 24/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -3669.7598 - val_acc: 0.0000e+00 - val_loss: -4578.3872\n",
      "Epoch 25/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -4245.4780 - val_acc: 0.0000e+00 - val_loss: -5345.3579\n",
      "Epoch 26/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -5043.5718 - val_acc: 0.0000e+00 - val_loss: -6202.0669\n",
      "Epoch 27/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -5801.9712 - val_acc: 0.0000e+00 - val_loss: -7138.9868\n",
      "Epoch 28/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -6401.1768 - val_acc: 0.0000e+00 - val_loss: -8207.5801\n",
      "Epoch 29/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -7598.0601 - val_acc: 0.0000e+00 - val_loss: -9369.0225\n",
      "Epoch 30/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -8502.2871 - val_acc: 0.0000e+00 - val_loss: -10649.0430\n",
      "Epoch 31/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -9952.2656 - val_acc: 0.0000e+00 - val_loss: -12063.8809\n",
      "Epoch 32/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -11205.1172 - val_acc: 0.0000e+00 - val_loss: -13608.5098\n",
      "Epoch 33/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -12588.6357 - val_acc: 0.0000e+00 - val_loss: -15300.2412\n",
      "Epoch 34/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -14129.6445 - val_acc: 0.0000e+00 - val_loss: -17149.0176\n",
      "Epoch 35/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -16091.7568 - val_acc: 0.0000e+00 - val_loss: -19144.0859\n",
      "Epoch 36/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -17464.4121 - val_acc: 0.0000e+00 - val_loss: -21339.4902\n",
      "Epoch 37/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -19313.7988 - val_acc: 0.0000e+00 - val_loss: -23693.9648\n",
      "Epoch 38/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -21427.4512 - val_acc: 0.0000e+00 - val_loss: -26243.0156\n",
      "Epoch 39/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -23531.8809 - val_acc: 0.0000e+00 - val_loss: -28981.2109\n",
      "Epoch 40/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -26528.1406 - val_acc: 0.0000e+00 - val_loss: -31940.9434\n",
      "Epoch 41/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -29844.9590 - val_acc: 0.0000e+00 - val_loss: -35131.8203\n",
      "Epoch 42/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -32360.3262 - val_acc: 0.0000e+00 - val_loss: -38507.8047\n",
      "Epoch 43/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -33645.6016 - val_acc: 0.0000e+00 - val_loss: -42231.0586\n",
      "Epoch 44/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -38338.1289 - val_acc: 0.0000e+00 - val_loss: -46073.3945\n",
      "Epoch 45/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -42147.7383 - val_acc: 0.0000e+00 - val_loss: -50240.5078\n",
      "Epoch 46/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -46508.8633 - val_acc: 0.0000e+00 - val_loss: -54691.5859\n",
      "Epoch 47/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -50087.3906 - val_acc: 0.0000e+00 - val_loss: -59420.3242\n",
      "Epoch 48/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -53451.3672 - val_acc: 0.0000e+00 - val_loss: -64495.0703\n",
      "Epoch 49/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -58258.5547 - val_acc: 0.0000e+00 - val_loss: -69770.5703\n",
      "Epoch 50/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -64165.8594 - val_acc: 0.0000e+00 - val_loss: -75408.6406\n",
      "Epoch 51/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -68775.2500 - val_acc: 0.0000e+00 - val_loss: -81454.6172\n",
      "Epoch 52/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -72204.3906 - val_acc: 0.0000e+00 - val_loss: -87874.2344\n",
      "Epoch 53/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -78462.3438 - val_acc: 0.0000e+00 - val_loss: -94583.0703\n",
      "Epoch 54/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -87333.1875 - val_acc: 0.0000e+00 - val_loss: -101646.8906\n",
      "Epoch 55/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -90770.6719 - val_acc: 0.0000e+00 - val_loss: -109153.1719\n",
      "Epoch 56/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -97856.6953 - val_acc: 0.0000e+00 - val_loss: -117070.5000\n",
      "Epoch 57/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -107259.5000 - val_acc: 0.0000e+00 - val_loss: -125370.7500\n",
      "Epoch 58/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -112953.0391 - val_acc: 0.0000e+00 - val_loss: -134161.0469\n",
      "Epoch 59/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -120508.1406 - val_acc: 0.0000e+00 - val_loss: -143359.6250\n",
      "Epoch 60/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -126133.7109 - val_acc: 0.0000e+00 - val_loss: -153019.8438\n",
      "Epoch 61/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -137767.4688 - val_acc: 0.0000e+00 - val_loss: -163152.7188\n",
      "Epoch 62/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -144513.7812 - val_acc: 0.0000e+00 - val_loss: -173873.0000\n",
      "Epoch 63/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -157618.6719 - val_acc: 0.0000e+00 - val_loss: -184952.1875\n",
      "Epoch 64/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -168611.3906 - val_acc: 0.0000e+00 - val_loss: -196679.6719\n",
      "Epoch 65/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -180112.8750 - val_acc: 0.0000e+00 - val_loss: -208846.6562\n",
      "Epoch 66/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -183123.1250 - val_acc: 0.0000e+00 - val_loss: -221669.3906\n",
      "Epoch 67/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -197920.8750 - val_acc: 0.0000e+00 - val_loss: -234942.9531\n",
      "Epoch 68/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -219341.7344 - val_acc: 0.0000e+00 - val_loss: -248887.5312\n",
      "Epoch 69/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -221951.8906 - val_acc: 0.0000e+00 - val_loss: -263537.8125\n",
      "Epoch 70/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -244507.9219 - val_acc: 0.0000e+00 - val_loss: -278607.5000\n",
      "Epoch 71/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -258080.9531 - val_acc: 0.0000e+00 - val_loss: -294558.5625\n",
      "Epoch 72/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -260402.8438 - val_acc: 0.0000e+00 - val_loss: -311202.0312\n",
      "Epoch 73/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -280538.9375 - val_acc: 0.0000e+00 - val_loss: -328501.1875\n",
      "Epoch 74/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -297200.2188 - val_acc: 0.0000e+00 - val_loss: -346388.6875\n",
      "Epoch 75/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -314082.9062 - val_acc: 0.0000e+00 - val_loss: -365036.4375\n",
      "Epoch 76/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -346274.9688 - val_acc: 0.0000e+00 - val_loss: -384225.1250\n",
      "Epoch 77/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -348018.4688 - val_acc: 0.0000e+00 - val_loss: -404543.2500\n",
      "Epoch 78/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -374701.8125 - val_acc: 0.0000e+00 - val_loss: -425202.5625\n",
      "Epoch 79/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -401395.0625 - val_acc: 0.0000e+00 - val_loss: -446752.3750\n",
      "Epoch 80/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -400957.0938 - val_acc: 0.0000e+00 - val_loss: -469617.4375\n",
      "Epoch 81/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -425928.0000 - val_acc: 0.0000e+00 - val_loss: -493024.3125\n",
      "Epoch 82/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -451115.7188 - val_acc: 0.0000e+00 - val_loss: -516995.3750\n",
      "Epoch 83/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -473754.1875 - val_acc: 0.0000e+00 - val_loss: -542218.7500\n",
      "Epoch 84/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -501012.9375 - val_acc: 0.0000e+00 - val_loss: -568029.2500\n",
      "Epoch 85/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -527884.5000 - val_acc: 0.0000e+00 - val_loss: -594921.5000\n",
      "Epoch 86/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -525491.8125 - val_acc: 0.0000e+00 - val_loss: -622970.3750\n",
      "Epoch 87/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -575265.8125 - val_acc: 0.0000e+00 - val_loss: -651497.5000\n",
      "Epoch 88/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -581641.8125 - val_acc: 0.0000e+00 - val_loss: -681392.8750\n",
      "Epoch 89/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -607353.5625 - val_acc: 0.0000e+00 - val_loss: -712542.5625\n",
      "Epoch 90/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -661593.9375 - val_acc: 0.0000e+00 - val_loss: -743963.9375\n",
      "Epoch 91/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -674525.6250 - val_acc: 0.0000e+00 - val_loss: -777035.6250\n",
      "Epoch 92/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -712757.0625 - val_acc: 0.0000e+00 - val_loss: -810870.8125\n",
      "Epoch 93/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -727598.2500 - val_acc: 0.0000e+00 - val_loss: -846222.8125\n",
      "Epoch 94/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -749659.9375 - val_acc: 0.0000e+00 - val_loss: -882505.2500\n",
      "Epoch 95/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -791351.6250 - val_acc: 0.0000e+00 - val_loss: -919747.5625\n",
      "Epoch 96/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -813082.6250 - val_acc: 0.0000e+00 - val_loss: -958229.5000\n",
      "Epoch 97/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -844060.2500 - val_acc: 0.0000e+00 - val_loss: -998346.0625\n",
      "Epoch 98/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -894944.3750 - val_acc: 0.0000e+00 - val_loss: -1038841.1875\n",
      "Epoch 99/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -951387.9375 - val_acc: 0.0000e+00 - val_loss: -1081436.8750\n",
      "Epoch 100/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -987064.6250 - val_acc: 0.0000e+00 - val_loss: -1124697.0000\n",
      "Epoch 1/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - acc: 0.0000e+00 - loss: 0.4070 - val_acc: 0.0000e+00 - val_loss: -1.3181\n",
      "Epoch 2/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -2.0845 - val_acc: 0.0000e+00 - val_loss: -7.5639\n",
      "Epoch 3/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -9.9257 - val_acc: 0.0000e+00 - val_loss: -26.5077\n",
      "Epoch 4/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -31.0921 - val_acc: 0.0000e+00 - val_loss: -67.5007\n",
      "Epoch 5/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -74.6511 - val_acc: 0.0000e+00 - val_loss: -143.1690\n",
      "Epoch 6/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -149.1422 - val_acc: 0.0000e+00 - val_loss: -266.0074\n",
      "Epoch 7/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -277.1434 - val_acc: 0.0000e+00 - val_loss: -457.0546\n",
      "Epoch 8/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -451.7588 - val_acc: 0.0000e+00 - val_loss: -739.4024\n",
      "Epoch 9/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -727.9186 - val_acc: 0.0000e+00 - val_loss: -1124.3044\n",
      "Epoch 10/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -1085.5436 - val_acc: 0.0000e+00 - val_loss: -1646.2096\n",
      "Epoch 11/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -1563.6670 - val_acc: 0.0000e+00 - val_loss: -2325.7695\n",
      "Epoch 12/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -2251.7761 - val_acc: 0.0000e+00 - val_loss: -3191.6687\n",
      "Epoch 13/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -3079.2566 - val_acc: 0.0000e+00 - val_loss: -4290.0718\n",
      "Epoch 14/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -4048.4080 - val_acc: 0.0000e+00 - val_loss: -5657.1152\n",
      "Epoch 15/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -5403.6504 - val_acc: 0.0000e+00 - val_loss: -7291.7153\n",
      "Epoch 16/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -6922.2227 - val_acc: 0.0000e+00 - val_loss: -9271.2881\n",
      "Epoch 17/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -8618.6553 - val_acc: 0.0000e+00 - val_loss: -11615.3516\n",
      "Epoch 18/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -10835.4160 - val_acc: 0.0000e+00 - val_loss: -14420.8096\n",
      "Epoch 19/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -13815.8057 - val_acc: 0.0000e+00 - val_loss: -17639.2930\n",
      "Epoch 20/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -16100.7295 - val_acc: 0.0000e+00 - val_loss: -21490.3555\n",
      "Epoch 21/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -19818.3223 - val_acc: 0.0000e+00 - val_loss: -25764.0664\n",
      "Epoch 22/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -24079.6094 - val_acc: 0.0000e+00 - val_loss: -30760.5039\n",
      "Epoch 23/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -29260.3516 - val_acc: 0.0000e+00 - val_loss: -36416.0664\n",
      "Epoch 24/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -33335.9453 - val_acc: 0.0000e+00 - val_loss: -42841.9336\n",
      "Epoch 25/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -38946.7109 - val_acc: 0.0000e+00 - val_loss: -50092.9961\n",
      "Epoch 26/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -46330.0664 - val_acc: 0.0000e+00 - val_loss: -58181.4375\n",
      "Epoch 27/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -53387.2539 - val_acc: 0.0000e+00 - val_loss: -67219.6250\n",
      "Epoch 28/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -61960.3047 - val_acc: 0.0000e+00 - val_loss: -77203.6094\n",
      "Epoch 29/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -72691.9062 - val_acc: 0.0000e+00 - val_loss: -88317.4766\n",
      "Epoch 30/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -76766.0156 - val_acc: 0.0000e+00 - val_loss: -100659.6719\n",
      "Epoch 31/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -92484.2500 - val_acc: 0.0000e+00 - val_loss: -114040.1953\n",
      "Epoch 32/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -104434.4922 - val_acc: 0.0000e+00 - val_loss: -129071.0859\n",
      "Epoch 33/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -118463.5859 - val_acc: 0.0000e+00 - val_loss: -145085.5938\n",
      "Epoch 34/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -131361.3906 - val_acc: 0.0000e+00 - val_loss: -162992.1406\n",
      "Epoch 35/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -148721.6875 - val_acc: 0.0000e+00 - val_loss: -182224.0781\n",
      "Epoch 36/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -166724.2656 - val_acc: 0.0000e+00 - val_loss: -203257.2969\n",
      "Epoch 37/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -187915.3281 - val_acc: 0.0000e+00 - val_loss: -225972.5000\n",
      "Epoch 38/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -206613.6719 - val_acc: 0.0000e+00 - val_loss: -250635.4062\n",
      "Epoch 39/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -230849.9688 - val_acc: 0.0000e+00 - val_loss: -277313.6250\n",
      "Epoch 40/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -246930.8281 - val_acc: 0.0000e+00 - val_loss: -306038.9375\n",
      "Epoch 41/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -267332.6875 - val_acc: 0.0000e+00 - val_loss: -336654.8438\n",
      "Epoch 42/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -298152.5625 - val_acc: 0.0000e+00 - val_loss: -369738.7500\n",
      "Epoch 43/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -332060.6875 - val_acc: 0.0000e+00 - val_loss: -404879.9375\n",
      "Epoch 44/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -370590.2500 - val_acc: 0.0000e+00 - val_loss: -442657.3750\n",
      "Epoch 45/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -397522.3438 - val_acc: 0.0000e+00 - val_loss: -483278.1250\n",
      "Epoch 46/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -437915.8438 - val_acc: 0.0000e+00 - val_loss: -526109.4375\n",
      "Epoch 47/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -484353.1562 - val_acc: 0.0000e+00 - val_loss: -571957.8750\n",
      "Epoch 48/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -515361.3125 - val_acc: 0.0000e+00 - val_loss: -620875.7500\n",
      "Epoch 49/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -566883.0000 - val_acc: 0.0000e+00 - val_loss: -673029.0000\n",
      "Epoch 50/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -596567.5625 - val_acc: 0.0000e+00 - val_loss: -728444.1875\n",
      "Epoch 51/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -646185.6250 - val_acc: 0.0000e+00 - val_loss: -786957.6250\n",
      "Epoch 52/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -727128.5625 - val_acc: 0.0000e+00 - val_loss: -848698.0625\n",
      "Epoch 53/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -769523.4375 - val_acc: 0.0000e+00 - val_loss: -914010.6875\n",
      "Epoch 54/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -833647.4375 - val_acc: 0.0000e+00 - val_loss: -983501.3125\n",
      "Epoch 55/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -885218.0000 - val_acc: 0.0000e+00 - val_loss: -1057196.8750\n",
      "Epoch 56/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -956231.5625 - val_acc: 0.0000e+00 - val_loss: -1133731.8750\n",
      "Epoch 57/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -1019076.3125 - val_acc: 0.0000e+00 - val_loss: -1216109.7500\n",
      "Epoch 58/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -1073316.3750 - val_acc: 0.0000e+00 - val_loss: -1301703.6250\n",
      "Epoch 59/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -1198506.6250 - val_acc: 0.0000e+00 - val_loss: -1391389.6250\n",
      "Epoch 60/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -1259440.5000 - val_acc: 0.0000e+00 - val_loss: -1486060.8750\n",
      "Epoch 61/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -1327429.5000 - val_acc: 0.0000e+00 - val_loss: -1585344.3750\n",
      "Epoch 62/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -1447784.1250 - val_acc: 0.0000e+00 - val_loss: -1689105.5000\n",
      "Epoch 63/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -1524883.0000 - val_acc: 0.0000e+00 - val_loss: -1798977.0000\n",
      "Epoch 64/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -1622916.3750 - val_acc: 0.0000e+00 - val_loss: -1913541.3750\n",
      "Epoch 65/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -1727067.5000 - val_acc: 0.0000e+00 - val_loss: -2033399.2500\n",
      "Epoch 66/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -1815342.6250 - val_acc: 0.0000e+00 - val_loss: -2159858.7500\n",
      "Epoch 67/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -1900642.3750 - val_acc: 0.0000e+00 - val_loss: -2291344.5000\n",
      "Epoch 68/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -2055167.2500 - val_acc: 0.0000e+00 - val_loss: -2427352.0000\n",
      "Epoch 69/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -2131874.7500 - val_acc: 0.0000e+00 - val_loss: -2570802.5000\n",
      "Epoch 70/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -2328999.7500 - val_acc: 0.0000e+00 - val_loss: -2720198.2500\n",
      "Epoch 71/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -2454196.7500 - val_acc: 0.0000e+00 - val_loss: -2875327.0000\n",
      "Epoch 72/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -2548827.7500 - val_acc: 0.0000e+00 - val_loss: -3039016.2500\n",
      "Epoch 73/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -2743688.7500 - val_acc: 0.0000e+00 - val_loss: -3208134.0000\n",
      "Epoch 74/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -2834123.0000 - val_acc: 0.0000e+00 - val_loss: -3385540.0000\n",
      "Epoch 75/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -3036624.0000 - val_acc: 0.0000e+00 - val_loss: -3566853.7500\n",
      "Epoch 76/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -3159239.2500 - val_acc: 0.0000e+00 - val_loss: -3757960.5000\n",
      "Epoch 77/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -3400818.7500 - val_acc: 0.0000e+00 - val_loss: -3956240.0000\n",
      "Epoch 78/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -3619527.2500 - val_acc: 0.0000e+00 - val_loss: -4162478.2500\n",
      "Epoch 79/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -3732702.2500 - val_acc: 0.0000e+00 - val_loss: -4377681.0000\n",
      "Epoch 80/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -3920345.2500 - val_acc: 0.0000e+00 - val_loss: -4600101.5000\n",
      "Epoch 81/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -4083141.0000 - val_acc: 0.0000e+00 - val_loss: -4830130.5000\n",
      "Epoch 82/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -4333259.0000 - val_acc: 0.0000e+00 - val_loss: -5069255.0000\n",
      "Epoch 83/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -4435449.5000 - val_acc: 0.0000e+00 - val_loss: -5318456.0000\n",
      "Epoch 84/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -4749500.5000 - val_acc: 0.0000e+00 - val_loss: -5574652.5000\n",
      "Epoch 85/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -4959820.5000 - val_acc: 0.0000e+00 - val_loss: -5840556.0000\n",
      "Epoch 86/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -5304629.0000 - val_acc: 0.0000e+00 - val_loss: -6112068.0000\n",
      "Epoch 87/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -5554072.5000 - val_acc: 0.0000e+00 - val_loss: -6396901.5000\n",
      "Epoch 88/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -5803028.0000 - val_acc: 0.0000e+00 - val_loss: -6692590.0000\n",
      "Epoch 89/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -5898066.5000 - val_acc: 0.0000e+00 - val_loss: -6998223.0000\n",
      "Epoch 90/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -6477139.5000 - val_acc: 0.0000e+00 - val_loss: -7309430.0000\n",
      "Epoch 91/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -6514209.0000 - val_acc: 0.0000e+00 - val_loss: -7636542.5000\n",
      "Epoch 92/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -6932136.5000 - val_acc: 0.0000e+00 - val_loss: -7968134.0000\n",
      "Epoch 93/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -6988731.0000 - val_acc: 0.0000e+00 - val_loss: -8318080.0000\n",
      "Epoch 94/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -7576613.5000 - val_acc: 0.0000e+00 - val_loss: -8674957.0000\n",
      "Epoch 95/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -7560206.5000 - val_acc: 0.0000e+00 - val_loss: -9044398.0000\n",
      "Epoch 96/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -8469075.0000 - val_acc: 0.0000e+00 - val_loss: -9421060.0000\n",
      "Epoch 97/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -8333035.5000 - val_acc: 0.0000e+00 - val_loss: -9816987.0000\n",
      "Epoch 98/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -8975631.0000 - val_acc: 0.0000e+00 - val_loss: -10222342.0000\n",
      "Epoch 99/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -9127951.0000 - val_acc: 0.0000e+00 - val_loss: -10638521.0000\n",
      "Epoch 100/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.0000e+00 - loss: -9590202.0000 - val_acc: 0.0000e+00 - val_loss: -11071252.0000\n",
      "Epoch 1/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.0000e+00 - loss: -0.4385 - val_acc: 0.0000e+00 - val_loss: -10.1743\n",
      "Epoch 2/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -17.3505 - val_acc: 0.0000e+00 - val_loss: -70.4035\n",
      "Epoch 3/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -89.0521 - val_acc: 0.0000e+00 - val_loss: -243.6453\n",
      "Epoch 4/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -287.3315 - val_acc: 0.0000e+00 - val_loss: -605.0238\n",
      "Epoch 5/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -669.9478 - val_acc: 0.0000e+00 - val_loss: -1270.8813\n",
      "Epoch 6/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -1319.9296 - val_acc: 0.0000e+00 - val_loss: -2366.3157\n",
      "Epoch 7/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -2415.6833 - val_acc: 0.0000e+00 - val_loss: -4002.3621\n",
      "Epoch 8/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -4077.3345 - val_acc: 0.0000e+00 - val_loss: -6373.5835\n",
      "Epoch 9/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -6192.6362 - val_acc: 0.0000e+00 - val_loss: -9665.2139\n",
      "Epoch 10/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -9725.4521 - val_acc: 0.0000e+00 - val_loss: -14043.9951\n",
      "Epoch 11/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -13488.7969 - val_acc: 0.0000e+00 - val_loss: -19812.7500\n",
      "Epoch 12/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -19327.2188 - val_acc: 0.0000e+00 - val_loss: -27138.8398\n",
      "Epoch 13/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -25649.5332 - val_acc: 0.0000e+00 - val_loss: -36251.2930\n",
      "Epoch 14/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.0000e+00 - loss: -33897.3047 - val_acc: 0.0000e+00 - val_loss: -47594.3906\n",
      "Epoch 15/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -45629.8594 - val_acc: 0.0000e+00 - val_loss: -61289.8125\n",
      "Epoch 16/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -56839.6914 - val_acc: 0.0000e+00 - val_loss: -77817.2266\n",
      "Epoch 17/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -74757.6641 - val_acc: 0.0000e+00 - val_loss: -97134.4375\n",
      "Epoch 18/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -91327.3672 - val_acc: 0.0000e+00 - val_loss: -119929.9219\n",
      "Epoch 19/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -114570.1172 - val_acc: 0.0000e+00 - val_loss: -146520.6406\n",
      "Epoch 20/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -134683.5469 - val_acc: 0.0000e+00 - val_loss: -177956.6250\n",
      "Epoch 21/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -165102.2188 - val_acc: 0.0000e+00 - val_loss: -213451.3281\n",
      "Epoch 22/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -200576.9688 - val_acc: 0.0000e+00 - val_loss: -254132.3750\n",
      "Epoch 23/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -238095.1406 - val_acc: 0.0000e+00 - val_loss: -299990.0625\n",
      "Epoch 24/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -281879.9375 - val_acc: 0.0000e+00 - val_loss: -351847.6875\n",
      "Epoch 25/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -321078.0312 - val_acc: 0.0000e+00 - val_loss: -410774.7500\n",
      "Epoch 26/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -372684.2812 - val_acc: 0.0000e+00 - val_loss: -475643.1562\n",
      "Epoch 27/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.0000e+00 - loss: -442065.4688 - val_acc: 0.0000e+00 - val_loss: -549131.9375\n",
      "Epoch 28/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -507734.4062 - val_acc: 0.0000e+00 - val_loss: -630471.8125\n",
      "Epoch 29/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -582344.2500 - val_acc: 0.0000e+00 - val_loss: -720188.6250\n",
      "Epoch 30/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -636373.3125 - val_acc: 0.0000e+00 - val_loss: -819392.1250\n",
      "Epoch 31/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -736517.5000 - val_acc: 0.0000e+00 - val_loss: -927695.0000\n",
      "Epoch 32/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -819044.2500 - val_acc: 0.0000e+00 - val_loss: -1048146.1250\n",
      "Epoch 33/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -957128.6875 - val_acc: 0.0000e+00 - val_loss: -1177960.3750\n",
      "Epoch 34/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -1073602.7500 - val_acc: 0.0000e+00 - val_loss: -1320432.3750\n",
      "Epoch 35/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -1180837.3750 - val_acc: 0.0000e+00 - val_loss: -1474952.7500\n",
      "Epoch 36/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -1314540.0000 - val_acc: 0.0000e+00 - val_loss: -1642837.0000\n",
      "Epoch 37/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -1497380.0000 - val_acc: 0.0000e+00 - val_loss: -1823402.2500\n",
      "Epoch 38/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -1675482.7500 - val_acc: 0.0000e+00 - val_loss: -2018892.5000\n",
      "Epoch 39/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -1809830.6250 - val_acc: 0.0000e+00 - val_loss: -2231054.7500\n",
      "Epoch 40/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -2024955.8750 - val_acc: 0.0000e+00 - val_loss: -2459243.5000\n",
      "Epoch 41/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -2209585.2500 - val_acc: 0.0000e+00 - val_loss: -2703760.0000\n",
      "Epoch 42/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -2499684.0000 - val_acc: 0.0000e+00 - val_loss: -2965627.5000\n",
      "Epoch 43/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -2763671.7500 - val_acc: 0.0000e+00 - val_loss: -3244849.0000\n",
      "Epoch 44/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -2922307.7500 - val_acc: 0.0000e+00 - val_loss: -3545442.5000\n",
      "Epoch 45/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -3223656.7500 - val_acc: 0.0000e+00 - val_loss: -3865302.0000\n",
      "Epoch 46/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -3471235.0000 - val_acc: 0.0000e+00 - val_loss: -4205673.5000\n",
      "Epoch 47/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -3726651.7500 - val_acc: 0.0000e+00 - val_loss: -4573302.0000\n",
      "Epoch 48/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -4138419.0000 - val_acc: 0.0000e+00 - val_loss: -4956890.5000\n",
      "Epoch 49/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -4298516.5000 - val_acc: 0.0000e+00 - val_loss: -5368754.5000\n",
      "Epoch 50/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -4840207.0000 - val_acc: 0.0000e+00 - val_loss: -5804353.0000\n",
      "Epoch 51/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -5220775.0000 - val_acc: 0.0000e+00 - val_loss: -6266286.0000\n",
      "Epoch 52/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -5519694.5000 - val_acc: 0.0000e+00 - val_loss: -6757047.0000\n",
      "Epoch 53/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -6252712.5000 - val_acc: 0.0000e+00 - val_loss: -7273398.5000\n",
      "Epoch 54/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -6475564.5000 - val_acc: 0.0000e+00 - val_loss: -7813414.0000\n",
      "Epoch 55/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -6892552.5000 - val_acc: 0.0000e+00 - val_loss: -8392349.0000\n",
      "Epoch 56/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -7311082.5000 - val_acc: 0.0000e+00 - val_loss: -8997043.0000\n",
      "Epoch 57/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -7973275.0000 - val_acc: 0.0000e+00 - val_loss: -9635595.0000\n",
      "Epoch 58/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -8555696.0000 - val_acc: 0.0000e+00 - val_loss: -10305074.0000\n",
      "Epoch 59/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -9467880.0000 - val_acc: 0.0000e+00 - val_loss: -11008782.0000\n",
      "Epoch 60/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -10057844.0000 - val_acc: 0.0000e+00 - val_loss: -11755954.0000\n",
      "Epoch 61/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -10408922.0000 - val_acc: 0.0000e+00 - val_loss: -12533954.0000\n",
      "Epoch 62/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -11245625.0000 - val_acc: 0.0000e+00 - val_loss: -13356496.0000\n",
      "Epoch 63/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -12154917.0000 - val_acc: 0.0000e+00 - val_loss: -14204790.0000\n",
      "Epoch 64/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -12421694.0000 - val_acc: 0.0000e+00 - val_loss: -15112290.0000\n",
      "Epoch 65/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -13607281.0000 - val_acc: 0.0000e+00 - val_loss: -16046057.0000\n",
      "Epoch 66/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -14252450.0000 - val_acc: 0.0000e+00 - val_loss: -17028784.0000\n",
      "Epoch 67/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -15354089.0000 - val_acc: 0.0000e+00 - val_loss: -18046072.0000\n",
      "Epoch 68/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -16435424.0000 - val_acc: 0.0000e+00 - val_loss: -19108838.0000\n",
      "Epoch 69/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -17332382.0000 - val_acc: 0.0000e+00 - val_loss: -20229482.0000\n",
      "Epoch 70/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -17866266.0000 - val_acc: 0.0000e+00 - val_loss: -21404608.0000\n",
      "Epoch 71/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -19085550.0000 - val_acc: 0.0000e+00 - val_loss: -22614686.0000\n",
      "Epoch 72/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -20210834.0000 - val_acc: 0.0000e+00 - val_loss: -23869572.0000\n",
      "Epoch 73/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -21179420.0000 - val_acc: 0.0000e+00 - val_loss: -25202656.0000\n",
      "Epoch 74/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -22792420.0000 - val_acc: 0.0000e+00 - val_loss: -26569492.0000\n",
      "Epoch 75/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -23418648.0000 - val_acc: 0.0000e+00 - val_loss: -27997356.0000\n",
      "Epoch 76/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -25173618.0000 - val_acc: 0.0000e+00 - val_loss: -29470562.0000\n",
      "Epoch 77/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -26502892.0000 - val_acc: 0.0000e+00 - val_loss: -31026908.0000\n",
      "Epoch 78/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -27356988.0000 - val_acc: 0.0000e+00 - val_loss: -32623460.0000\n",
      "Epoch 79/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -29673588.0000 - val_acc: 0.0000e+00 - val_loss: -34276556.0000\n",
      "Epoch 80/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -30176162.0000 - val_acc: 0.0000e+00 - val_loss: -36002880.0000\n",
      "Epoch 81/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -32087524.0000 - val_acc: 0.0000e+00 - val_loss: -37783192.0000\n",
      "Epoch 82/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -33038450.0000 - val_acc: 0.0000e+00 - val_loss: -39642716.0000\n",
      "Epoch 83/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -35615068.0000 - val_acc: 0.0000e+00 - val_loss: -41557780.0000\n",
      "Epoch 84/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -36377656.0000 - val_acc: 0.0000e+00 - val_loss: -43558292.0000\n",
      "Epoch 85/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -40702164.0000 - val_acc: 0.0000e+00 - val_loss: -45593364.0000\n",
      "Epoch 86/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -39762836.0000 - val_acc: 0.0000e+00 - val_loss: -47743020.0000\n",
      "Epoch 87/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -42730264.0000 - val_acc: 0.0000e+00 - val_loss: -49933208.0000\n",
      "Epoch 88/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -44959112.0000 - val_acc: 0.0000e+00 - val_loss: -52203200.0000\n",
      "Epoch 89/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.0000e+00 - loss: -46675008.0000 - val_acc: 0.0000e+00 - val_loss: -54578708.0000\n",
      "Epoch 90/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -49013412.0000 - val_acc: 0.0000e+00 - val_loss: -57013696.0000\n",
      "Epoch 91/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -50801336.0000 - val_acc: 0.0000e+00 - val_loss: -59539676.0000\n",
      "Epoch 92/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -53717816.0000 - val_acc: 0.0000e+00 - val_loss: -62142620.0000\n",
      "Epoch 93/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -57209456.0000 - val_acc: 0.0000e+00 - val_loss: -64844152.0000\n",
      "Epoch 94/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -56657716.0000 - val_acc: 0.0000e+00 - val_loss: -67620816.0000\n",
      "Epoch 95/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -60702276.0000 - val_acc: 0.0000e+00 - val_loss: -70477888.0000\n",
      "Epoch 96/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -64087912.0000 - val_acc: 0.0000e+00 - val_loss: -73440512.0000\n",
      "Epoch 97/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -64532932.0000 - val_acc: 0.0000e+00 - val_loss: -76483568.0000\n",
      "Epoch 98/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -68176536.0000 - val_acc: 0.0000e+00 - val_loss: -79633696.0000\n",
      "Epoch 99/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -70059168.0000 - val_acc: 0.0000e+00 - val_loss: -82900920.0000\n",
      "Epoch 100/100\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.0000e+00 - loss: -75163368.0000 - val_acc: 0.0000e+00 - val_loss: -86182504.0000\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history1 = model1.fit(train_data, train_labels, epochs=100, batch_size=512, validation_data=(val_data, val_labels), class_weight=class_weight)\n",
    "history2 = model2.fit(train_data, train_labels, epochs=100, batch_size=512, validation_data=(val_data, val_labels), class_weight=class_weight)\n",
    "history3 = model3.fit(train_data, train_labels, epochs=100, batch_size=512, validation_data=(val_data, val_labels), class_weight=class_weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_accuracy(history1, history2, history3, 'Model 1', 'Model 2', 'Model 3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
