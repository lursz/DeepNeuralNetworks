{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# !LD_LIBRARY_PATH=$HOME/miniconda3/lib:$LD_LIBRARY_PATH\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.14.1\n",
      "Keras version: 2.14.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os, shutil\n",
    "\n",
    "print (\"TensorFlow version: \" + tf.__version__)\n",
    "print (\"Keras version: \" + keras.__version__)\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_confusion_matrix_for_models(X_test, Y_test, *models) -> None:\n",
    "    \"\"\"\n",
    "    Visualizes the confusion matrices for multiple machine learning models.\n",
    "\n",
    "    Parameters:\n",
    "        X_test (array-like): Test data features.\n",
    "        Y_test (array-like): True labels for the test data.\n",
    "        *models (variable-length argument list): Machine learning models to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        None. Displays confusion matrices using seaborn's heatmap.\n",
    "    \"\"\"\n",
    "    num_models = len(models)\n",
    "    plt.figure(figsize=(5 * num_models, 5))\n",
    "    for i, model in enumerate(models, 1):\n",
    "        plt.subplot(1, num_models, i)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        Y_pred = (Y_pred > 0.5)\n",
    "        matrix = metrics.confusion_matrix(Y_test, Y_pred)\n",
    "        hm = sns.heatmap(matrix,\n",
    "                         cmap='coolwarm',\n",
    "                         linecolor='white',\n",
    "                         linewidths=1,\n",
    "                         annot=True,\n",
    "                         fmt='d')\n",
    "        plt.yticks(rotation=0)\n",
    "        hm.set_ylim(0, len(matrix))\n",
    "        plt.title(f'Confusion Matrix - Model {i}')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_accuracy_comparison(*histories, labels: list[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Plots the training and validation accuracy comparison for multiple models.\n",
    "\n",
    "    Args:\n",
    "    *histories: Variable number of history objects. Each history object should contain\n",
    "                training and validation accuracy values.\n",
    "    labels: List of labels for each model.\n",
    "    \"\"\"\n",
    "    plt.rcParams['figure.figsize'] = (25.0, 5.0)  # set default size of plots\n",
    "    epochs = range(1, len(histories[0].history['acc']) + 1)  # Assuming all models have the same number of epochs\n",
    "\n",
    "    for i, history in enumerate(histories):\n",
    "        color = ['b', 'r', 'g', 'c', 'm', 'y'][i % 6]  # Choose color cyclically\n",
    "        label = labels[i] if labels else f'Model {i+1}'\n",
    "        acc = history.history['acc']\n",
    "        val_acc = history.history['val_acc']\n",
    "        plt.plot(epochs, acc, color + 'o', label=f'Training accuracy for {label}')\n",
    "        plt.plot(epochs, val_acc, color, label=f'Validation accuracy for {label}')\n",
    "\n",
    "    plt.title('Comparison of Training and Validation Accuracies')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_loss_comparison(*histories, labels: list[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Plots the training and validation loss comparison for multiple models.\n",
    "\n",
    "    Args:\n",
    "    *histories: Variable number of history objects. Each history object should contain\n",
    "                training and validation loss values.\n",
    "    labels: List of labels for each model.\n",
    "    \"\"\"\n",
    "    plt.rcParams['figure.figsize'] = (25.0, 5.0)  # set default size of plots\n",
    "    epochs = range(1, len(histories[0].history['loss']) + 1)  # Assuming all models have the same number of epochs\n",
    "\n",
    "    for i, history in enumerate(histories):\n",
    "        color = ['b', 'r', 'g', 'c', 'm', 'y'][i % 6]  # Choose color cyclically\n",
    "        label = labels[i] if labels else f'Model {i+1}'\n",
    "        loss = history.history['loss']\n",
    "        val_loss = history.history['val_loss']\n",
    "        plt.plot(epochs, loss, color + 'o', label=f'Training loss for {label}')\n",
    "        plt.plot(epochs, val_loss, color, label=f'Validation loss for {label}')\n",
    "\n",
    "    plt.title('Comparison of Training and Validation Losses')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def print_val_accuracies(history1, history2, history3):\n",
    "    val_accuracy1 = history1.history['val_acc']\n",
    "    val_accuracy2 = history2.history['val_acc']\n",
    "    val_accuracy3 = history3.history['val_acc']\n",
    "\n",
    "    argmax1 = np.argmax(val_accuracy1)\n",
    "    argmax2 = np.argmax(val_accuracy2)\n",
    "    argmax3 = np.argmax(val_accuracy3)\n",
    "\n",
    "    print ('Max accuracy for model 1 is: ', val_accuracy1[argmax1], ', achieved in the ', argmax1 , 'epoch.')\n",
    "    print ('Max accuracy for model 2 is: ', val_accuracy2[argmax2], ', achieved in the ', argmax2 , 'epoch.')\n",
    "    print ('Max accuracy for model 3 is: ', val_accuracy3[argmax3], ', achieved in the ', argmax3 , 'epoch.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_dir = \"kaggle\"\n",
    "    \n",
    "processed_dir = kaggle_dir + \"/processed\"\n",
    "\n",
    "cats_and_dogs_small_dir = processed_dir + \"/cats_and_dogs_small\"\n",
    "\n",
    "base_dir = cats_and_dogs_small_dir + \"/\"\n",
    "\n",
    "train_dir: str = base_dir + \"train/\"\n",
    "\n",
    "train_cats_dir: str = train_dir + \"cats/\"\n",
    "train_dogs_dir: str = train_dir + \"dogs/\"\n",
    "\n",
    "validation_dir: str = base_dir + \"validation/\"\n",
    "\n",
    "validation_cats_dir: str = validation_dir + \"cats/\"\n",
    "validation_dogs_dir: str = validation_dir + \"dogs/\"\n",
    "\n",
    "test_dir: str = base_dir + \"test/\"\n",
    "\n",
    "test_cats_dir: str = test_dir + \"cats/\"\n",
    "test_dogs_dir: str = test_dir + \"dogs/\"\n",
    "\n",
    "models_dir: str = \"models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def create_dir_if_not_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def create_dirs():\n",
    "    all_paths: list[str] = [kaggle_dir, processed_dir, cats_and_dogs_small_dir,\n",
    "                            base_dir, train_dir, train_cats_dir, train_dogs_dir, validation_cats_dir, validation_dogs_dir, test_cats_dir, test_dogs_dir]\n",
    "    \n",
    "    for path in all_paths:\n",
    "        create_dir_if_not_exists(path)\n",
    "\n",
    "def copy_train_images(indices: np.ndarray, animal: str ='cat', dir_type: str ='train'):\n",
    "    for index in indices:\n",
    "        src: str = f\"kaggle/original/train/{animal}.{index}.jpg\"\n",
    "        dst: str = f\"kaggle/processed/cats_and_dogs_small/{dir_type}/{animal}s/{animal}.{index}.jpg\"\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "def remove_images():\n",
    "    if os.path.exists(base_dir):\n",
    "        shutil.rmtree(base_dir, ignore_errors=True)\n",
    "\n",
    "def copy_all_images(validation_size=500, test_size=1000, max_train_size=20000):\n",
    "    remove_images()\n",
    "\n",
    "    create_dirs()\n",
    "    print(\"Dirs created\")\n",
    "    \n",
    "    files: list[str] = os.listdir(\"kaggle/original/train\")\n",
    "\n",
    "    cats_count: int = sum(1 for file in files if file.startswith(\"cat\"))\n",
    "    dogs_count: int = sum(1 for file in files if file.startswith(\"dog\"))\n",
    "\n",
    "    train_size_cats: int = min(cats_count - validation_size - test_size, max_train_size)\n",
    "    train_size_dogs: int = min(dogs_count - validation_size - test_size, max_train_size)\n",
    "\n",
    "    indices_cats = np.random.permutation(cats_count)\n",
    "    indices_dogs = np.random.permutation(dogs_count)\n",
    "\n",
    "    indices_cats_train = indices_cats[:train_size_cats]\n",
    "    indices_dogs_train = indices_dogs[:train_size_dogs]\n",
    "\n",
    "    indices_cats_validation = indices_cats[train_size_cats:train_size_cats + validation_size]\n",
    "    indices_dogs_validation = indices_dogs[train_size_dogs:train_size_dogs + validation_size]\n",
    "\n",
    "    indices_cats_test = indices_cats[train_size_cats + validation_size:train_size_cats + validation_size + test_size]\n",
    "    indices_dogs_test = indices_dogs[train_size_dogs + validation_size:train_size_dogs + validation_size + test_size]\n",
    "\n",
    "\n",
    "    copy_train_images(indices_cats_train, 'cat', 'train')\n",
    "    copy_train_images(indices_dogs_train, 'dog', 'train')\n",
    "    print(\"Train images copied\")\n",
    "\n",
    "    copy_train_images(indices_cats_validation, 'cat', 'validation')\n",
    "    copy_train_images(indices_dogs_validation, 'dog', 'validation')\n",
    "    print(\"Validation images copied\")\n",
    "\n",
    "    copy_train_images(indices_cats_test, 'cat', 'test')\n",
    "    copy_train_images(indices_dogs_test, 'dog', 'test')\n",
    "    print(\"Test images copied\")\n",
    "\n",
    "    print(\"All images copied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dirs created\n",
      "Train images copied\n",
      "Validation images copied\n",
      "Test images copied\n",
      "All images copied\n"
     ]
    }
   ],
   "source": [
    "copy_all_images(max_train_size=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_count: int = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_208 (Conv2D)         (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_200 (MaxPool  (None, 74, 74, 32)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_209 (Conv2D)         (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_201 (MaxPool  (None, 36, 36, 64)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_210 (Conv2D)         (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_202 (MaxPool  (None, 17, 17, 128)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_211 (Conv2D)         (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_203 (MaxPool  (None, 7, 7, 128)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_212 (Conv2D)         (None, 5, 5, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_204 (MaxPool  (None, 2, 2, 128)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_144 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 520001 (1.98 MB)\n",
      "Trainable params: 520001 (1.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 150, 150\n",
    "\n",
    "model1 = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_213 (Conv2D)         (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_205 (MaxPool  (None, 74, 74, 32)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_214 (Conv2D)         (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_136 (B  (None, 72, 72, 64)        256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_206 (MaxPool  (None, 36, 36, 64)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_215 (Conv2D)         (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_137 (B  (None, 34, 34, 128)       512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_207 (MaxPool  (None, 17, 17, 128)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_216 (Conv2D)         (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_138 (B  (None, 15, 15, 128)       512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_208 (MaxPool  (None, 7, 7, 128)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_217 (Conv2D)         (None, 5, 5, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_139 (B  (None, 5, 5, 128)         512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_209 (MaxPool  (None, 2, 2, 128)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_145 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521793 (1.99 MB)\n",
      "Trainable params: 520897 (1.99 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                metrics=['acc'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_218 (Conv2D)         (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_210 (MaxPool  (None, 74, 74, 32)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_219 (Conv2D)         (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_140 (B  (None, 72, 72, 64)        256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_146 (Dropout)       (None, 72, 72, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_211 (MaxPool  (None, 36, 36, 64)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_220 (Conv2D)         (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_141 (B  (None, 34, 34, 128)       512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_147 (Dropout)       (None, 34, 34, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_212 (MaxPool  (None, 17, 17, 128)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_221 (Conv2D)         (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_142 (B  (None, 15, 15, 128)       512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_148 (Dropout)       (None, 15, 15, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_213 (MaxPool  (None, 7, 7, 128)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_222 (Conv2D)         (None, 5, 5, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_143 (B  (None, 5, 5, 128)         512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_149 (Dropout)       (None, 5, 5, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_214 (MaxPool  (None, 2, 2, 128)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " flatten_42 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_150 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521793 (1.99 MB)\n",
      "Trainable params: 520897 (1.99 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model3.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                metrics=['acc'])\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_223 (Conv2D)         (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_215 (MaxPool  (None, 74, 74, 32)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_224 (Conv2D)         (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_144 (B  (None, 72, 72, 64)        256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       (None, 72, 72, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_216 (MaxPool  (None, 36, 36, 64)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_225 (Conv2D)         (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_145 (B  (None, 34, 34, 128)       512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_152 (Dropout)       (None, 34, 34, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_217 (MaxPool  (None, 17, 17, 128)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_226 (Conv2D)         (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_146 (B  (None, 15, 15, 128)       512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_153 (Dropout)       (None, 15, 15, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_218 (MaxPool  (None, 7, 7, 128)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_227 (Conv2D)         (None, 5, 5, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_147 (B  (None, 5, 5, 128)         512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_154 (Dropout)       (None, 5, 5, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_219 (MaxPool  (None, 2, 2, 128)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " flatten_43 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_155 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521793 (1.99 MB)\n",
      "Trainable params: 520897 (1.99 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='LeakyReLU'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='LeakyReLU'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(256, activation='LeakyReLU'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model4.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                metrics=['acc'])\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_234 (Conv2D)         (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_225 (MaxPool  (None, 74, 74, 32)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_235 (Conv2D)         (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_153 (B  (None, 72, 72, 64)        256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_162 (Dropout)       (None, 72, 72, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_226 (MaxPool  (None, 36, 36, 64)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_236 (Conv2D)         (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_154 (B  (None, 34, 34, 128)       512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_163 (Dropout)       (None, 34, 34, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_227 (MaxPool  (None, 17, 17, 128)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_237 (Conv2D)         (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_155 (B  (None, 15, 15, 128)       512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_164 (Dropout)       (None, 15, 15, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_228 (MaxPool  (None, 7, 7, 128)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_238 (Conv2D)         (None, 5, 5, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_156 (B  (None, 5, 5, 128)         512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_165 (Dropout)       (None, 5, 5, 128)         0         \n",
      "                                                                 \n",
      " conv2d_239 (Conv2D)         (None, 3, 3, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_157 (B  (None, 3, 3, 128)         512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_166 (Dropout)       (None, 3, 3, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_229 (MaxPool  (None, 1, 1, 128)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " flatten_45 (Flatten)        (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_167 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 571585 (2.18 MB)\n",
      "Trainable params: 570433 (2.18 MB)\n",
      "Non-trainable params: 1152 (4.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(128, (3, 3), activation='LeakyReLU'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model5.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                metrics=['acc'])\n",
    "\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=32, #32\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=32, #32\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history1 = model1.fit_generator(\n",
    "history1 = model1.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=epochs_count,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)\n",
    "\n",
    "history2 = model2.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=epochs_count,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 20:56:31.439205: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_42/dropout_146/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 1.1917 - acc: 0.5038WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 23s 202ms/step - loss: 1.1917 - acc: 0.5038 - val_loss: 0.7327 - val_acc: 0.5000\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 20:56:53.080833: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 16111537446917608171\n",
      "2024-04-11 20:56:53.080912: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 2845362583814793090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 17s 166ms/step - loss: 1.0197 - acc: 0.5375\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.9327 - acc: 0.5478\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 15s 150ms/step - loss: 0.8859 - acc: 0.5606\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.8656 - acc: 0.5397\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 15s 150ms/step - loss: 0.8481 - acc: 0.5422\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.8209 - acc: 0.5638\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 0.8003 - acc: 0.5484\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 18s 176ms/step - loss: 0.8092 - acc: 0.5409\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 15s 154ms/step - loss: 0.8077 - acc: 0.5437\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.7931 - acc: 0.5578\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 15s 154ms/step - loss: 0.7805 - acc: 0.5525\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.7734 - acc: 0.5550\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 0.7561 - acc: 0.5716\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 0.7434 - acc: 0.5697\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.7621 - acc: 0.5741\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 19s 189ms/step - loss: 0.7586 - acc: 0.5763\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.7461 - acc: 0.5853\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.7488 - acc: 0.5684\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 0.7348 - acc: 0.5809\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.7420 - acc: 0.5700\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.7250 - acc: 0.5781\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 0.7161 - acc: 0.5928\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.7197 - acc: 0.5944\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 0.7264 - acc: 0.5841\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.7078 - acc: 0.5962\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.6990 - acc: 0.6175\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.7064 - acc: 0.6031\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.6878 - acc: 0.6109\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.6923 - acc: 0.6175\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 15s 146ms/step - loss: 0.6911 - acc: 0.6141\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 15s 149ms/step - loss: 0.6691 - acc: 0.6341\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 17s 149ms/step - loss: 0.6814 - acc: 0.6097\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 15s 145ms/step - loss: 0.6872 - acc: 0.6047\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.6748 - acc: 0.6209\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 15s 144ms/step - loss: 0.6713 - acc: 0.6403\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.6693 - acc: 0.6328\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.6675 - acc: 0.6284\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 17s 173ms/step - loss: 0.6657 - acc: 0.6363\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 16s 155ms/step - loss: 0.6655 - acc: 0.6309\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 0.6534 - acc: 0.6403\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 0.6593 - acc: 0.6388\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.6518 - acc: 0.6472\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.6441 - acc: 0.6394\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 18s 176ms/step - loss: 0.6451 - acc: 0.6469\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 16s 155ms/step - loss: 0.6443 - acc: 0.6481\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 18s 176ms/step - loss: 0.6249 - acc: 0.6572\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 0.6236 - acc: 0.6637\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 0.6291 - acc: 0.6653\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 16s 156ms/step - loss: 0.6258 - acc: 0.6728\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=epochs_count,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 21:10:12.638923: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_43/dropout_151/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 1.2378 - acc: 0.5225WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 23s 203ms/step - loss: 1.2378 - acc: 0.5225 - val_loss: 0.9355 - val_acc: 0.5000\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 21:10:34.262046: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 16111537446917608171\n",
      "2024-04-11 21:10:34.262117: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 2845362583814793090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 16s 156ms/step - loss: 1.0500 - acc: 0.5309\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 18s 176ms/step - loss: 0.9672 - acc: 0.5216\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 16s 154ms/step - loss: 0.9367 - acc: 0.5222\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 18s 175ms/step - loss: 0.8569 - acc: 0.5497\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 0.8346 - acc: 0.5500\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 0.8237 - acc: 0.5434\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 16s 156ms/step - loss: 0.8184 - acc: 0.5584\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 18s 174ms/step - loss: 0.8077 - acc: 0.5375\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 0.7989 - acc: 0.5572\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.7584 - acc: 0.5788\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.7560 - acc: 0.5766\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.7739 - acc: 0.5472\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 0.7671 - acc: 0.5472\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 15s 145ms/step - loss: 0.7467 - acc: 0.5591\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.7554 - acc: 0.5659\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 0.7371 - acc: 0.5775\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.7292 - acc: 0.5806\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 0.7326 - acc: 0.5750\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.7308 - acc: 0.5850\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.6953 - acc: 0.6047\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.7331 - acc: 0.5697\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 0.7072 - acc: 0.5938\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.7132 - acc: 0.5922\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 15s 145ms/step - loss: 0.7086 - acc: 0.5956\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 0.7022 - acc: 0.5888\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.6963 - acc: 0.6084\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 15s 145ms/step - loss: 0.6908 - acc: 0.6019\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 16s 165ms/step - loss: 0.6775 - acc: 0.6291\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 15s 151ms/step - loss: 0.6762 - acc: 0.6128\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 0.6741 - acc: 0.6187\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.6700 - acc: 0.6209\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 0.6663 - acc: 0.6256\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 16s 155ms/step - loss: 0.6655 - acc: 0.6369\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.6742 - acc: 0.6119\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.6644 - acc: 0.6275\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 17s 171ms/step - loss: 0.6451 - acc: 0.6406\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.6723 - acc: 0.6300\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.6543 - acc: 0.6425\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 0.6429 - acc: 0.6406\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 0.6447 - acc: 0.6475\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 0.6398 - acc: 0.6488\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.6271 - acc: 0.6547\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 16s 156ms/step - loss: 0.6434 - acc: 0.6559\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.6402 - acc: 0.6400\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 16s 163ms/step - loss: 0.6225 - acc: 0.6650\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.6340 - acc: 0.6556\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 0.6439 - acc: 0.6491\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.6334 - acc: 0.6562\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.6146 - acc: 0.6759\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=epochs_count,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 21:23:49.461534: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_44/dropout_156/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.7708 - acc: 0.5434WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 21s 188ms/step - loss: 0.7708 - acc: 0.5434 - val_loss: 0.7493 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 0.7373 - acc: 0.5616\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 0.7094 - acc: 0.5625\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 0.7010 - acc: 0.5819\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 0.6888 - acc: 0.5919\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.6882 - acc: 0.5797\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 0.6804 - acc: 0.5944\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 16s 162ms/step - loss: 0.6782 - acc: 0.5984\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.6619 - acc: 0.6137\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 17s 166ms/step - loss: 0.6776 - acc: 0.6084\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.6635 - acc: 0.6147\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.6573 - acc: 0.6141\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 0.6359 - acc: 0.6309\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 0.6424 - acc: 0.6384\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.6349 - acc: 0.6519\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 0.6265 - acc: 0.6531\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.6163 - acc: 0.6622\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 16s 160ms/step - loss: 0.6337 - acc: 0.6428\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 17s 173ms/step - loss: 0.6281 - acc: 0.6531\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 0.6123 - acc: 0.6697\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 18s 175ms/step - loss: 0.6115 - acc: 0.6628\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 15s 154ms/step - loss: 0.6010 - acc: 0.6791\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.5829 - acc: 0.6953\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 0.5918 - acc: 0.6928\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 17s 173ms/step - loss: 0.5981 - acc: 0.6809\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.5816 - acc: 0.6919\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 17s 169ms/step - loss: 0.5884 - acc: 0.6875\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.5693 - acc: 0.7038\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.5724 - acc: 0.7106\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 0.5627 - acc: 0.7119\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 17s 173ms/step - loss: 0.5590 - acc: 0.7109\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 16s 155ms/step - loss: 0.5673 - acc: 0.7000\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 18s 176ms/step - loss: 0.5514 - acc: 0.7172\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 0.5453 - acc: 0.7241\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.5552 - acc: 0.7138\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 15s 146ms/step - loss: 0.5414 - acc: 0.7259\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 17s 165ms/step - loss: 0.5452 - acc: 0.7188\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.5300 - acc: 0.7312\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.5282 - acc: 0.7334\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 15s 149ms/step - loss: 0.5253 - acc: 0.7359\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 17s 167ms/step - loss: 0.5181 - acc: 0.7406\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 0.5224 - acc: 0.7328\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.5363 - acc: 0.7291\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.5000 - acc: 0.7616\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 20s 199ms/step - loss: 0.5075 - acc: 0.7475\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 18s 176ms/step - loss: 0.4924 - acc: 0.7534\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 17s 168ms/step - loss: 0.4975 - acc: 0.7578\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 0.5124 - acc: 0.7422\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 0.4897 - acc: 0.7553\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 18s 175ms/step - loss: 0.4882 - acc: 0.7625\n"
     ]
    }
   ],
   "source": [
    "history5 = model5.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=epochs_count,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenovo/miniconda3/envs/tf/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model1.save(models_dir + 'cats_and_dogs_small_1.h5')\n",
    "model2.save(models_dir + 'cats_and_dogs_small_2.h5')\n",
    "model3.save(models_dir + 'cats_and_dogs_small_3.h5')\n",
    "model4.save(models_dir + 'cats_and_dogs_small_4.h5')\n",
    "model5.save(models_dir + 'cats_and_dogs_small_5.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (50,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# plot_accuracy_comparison(history1, history2, labels=['Model 1', 'Model 2'])\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# plot_loss_comparison(history1, history2, labels=['Model 1', 'Model 2'])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print_val_accuracies(history1, history1, history1)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mplot_accuracy_comparison\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModel 3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModel 4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModel 5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m plot_loss_comparison(history3, history4, history5, labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel 3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel 4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel 5\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m print_val_accuracies(history3, history4, history5)\n",
      "Cell \u001b[0;32mIn[118], line 53\u001b[0m, in \u001b[0;36mplot_accuracy_comparison\u001b[0;34m(labels, *histories)\u001b[0m\n\u001b[1;32m     51\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     52\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(epochs, acc, color \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining accuracy for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_acc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mValidation accuracy for \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlabel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComparison of Training and Validation Accuracies\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     56\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/matplotlib/pyplot.py:3578\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3570\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3572\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3576\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3577\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3583\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3584\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/matplotlib/axes/_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1721\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/matplotlib/axes/_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/matplotlib/axes/_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy_comparison(history1, history2, history3, history4, history5, labels=['Model 1', 'Model 2', 'Model 3', 'Model 4', 'Model 5'])\n",
    "plot_loss_comparison(history1, history2, history3, history4, history5, labels=['Model 1', 'Model 2', 'Model 3', 'Model 4', 'Model 5'])\n",
    "print_val_accuracies(history1, history2, history3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increase number of training samples - 12000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_all_images(max_train_size=12000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 150, 150\n",
    "\n",
    "model6 = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model6.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model7.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                metrics=['acc'])\n",
    "\n",
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model8.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                metrics=['acc'])\n",
    "\n",
    "model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model9 = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='LeakyReLU'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='LeakyReLU'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(256, activation='LeakyReLU'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model9.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                metrics=['acc'])\n",
    "\n",
    "model9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10 = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(128, (3, 3), activation='LeakyReLU'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model5.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                metrics=['acc'])\n",
    "\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history6 = model6.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=epochs_count,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history7 = model7.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=epochs_count,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history8 = model8.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=epochs_count,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history9 = model9.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=epochs_count,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history10 = model10.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=epochs_count,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.save(models_dir + 'cats_and_dogs_small_6.h5')\n",
    "model7.save(models_dir + 'cats_and_dogs_small_7.h5')\n",
    "model8.save(models_dir + 'cats_and_dogs_small_8.h5')\n",
    "model9.save(models_dir + 'cats_and_dogs_small_9.h5')\n",
    "model10.save(models_dir + 'cats_and_dogs_small_10.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_comparison(history6, history7, history8, history9, history10, labels=['Model 6', 'Model 7', 'Model 8', 'Model 9', 'Model 10'])\n",
    "plot_loss_comparison(history6, history7, history8, history9, history10, labels=['Model 6', 'Model 7', 'Model 8', 'Model 9', 'Model 10'])\n",
    "print_val_accuracies(history6, history7, history8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increase number of training samples - 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_all_images(max_train_size=12000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 150, 150\n",
    "\n",
    "model11 = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model11.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "model11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_240 (Conv2D)         (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_230 (MaxPool  (None, 74, 74, 32)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_241 (Conv2D)         (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_158 (B  (None, 72, 72, 64)        256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_231 (MaxPool  (None, 36, 36, 64)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_242 (Conv2D)         (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_159 (B  (None, 34, 34, 128)       512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_232 (MaxPool  (None, 17, 17, 128)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_243 (Conv2D)         (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_160 (B  (None, 15, 15, 128)       512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_233 (MaxPool  (None, 7, 7, 128)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_244 (Conv2D)         (None, 5, 5, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_161 (B  (None, 5, 5, 128)         512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_234 (MaxPool  (None, 2, 2, 128)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " flatten_46 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_168 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521793 (1.99 MB)\n",
      "Trainable params: 520897 (1.99 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model12 = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model12.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                metrics=['acc'])\n",
    "\n",
    "model12.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model13 = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model13.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                metrics=['acc'])\n",
    "\n",
    "model13.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model14 = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='LeakyReLU'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='LeakyReLU'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(256, activation='LeakyReLU'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model14.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                metrics=['acc'])\n",
    "\n",
    "model14.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model15 = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(128, (3, 3), activation='LeakyReLU'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model15.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                metrics=['acc'])\n",
    "\n",
    "model15.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history11 = model11.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=epochs_count,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history12 = model12.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=epochs_count,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history13 = model13.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=epochs_count,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history14 = model14.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=epochs_count,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history15 = model15.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=epochs_count,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model11.save(models_dir + 'cats_and_dogs_small_11.h5')\n",
    "model12.save(models_dir + 'cats_and_dogs_small_12.h5')\n",
    "model13.save(models_dir + 'cats_and_dogs_small_13.h5')\n",
    "model14.save(models_dir + 'cats_and_dogs_small_14.h5')\n",
    "model15.save(models_dir + 'cats_and_dogs_small_15.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_comparison(history11, history12, history13, history14, history15, labels=['Model 11', 'Model 12', 'Model 13', 'Model 14', 'Model 15'])\n",
    "plot_loss_comparison(history11, history12, history13, history14, history15, labels=['Model 11', 'Model 12', 'Model 13', 'Model 14', 'Model 15'])\n",
    "print_val_accuracies(history11, history12, history13)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
